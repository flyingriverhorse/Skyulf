# © 2025 Murat Unsal — Skyulf Project
# Environment Configuration Template
# Copy this file to .env and fill in your own values

# ====== Primary Database Configuration ======
# Options: sqlite, postgres
DB_TYPE=sqlite
DB_PATH=mlops_database.db
DB_PRIMARY=sqlite
USE_DATABASE_STORAGE=true

# ====== PostgreSQL Configuration (Optional) ======
# Uncomment and configure if using PostgreSQL
# DATABASE_URL=postgresql+psycopg2://username:password@host:port/database?sslmode=prefer
# DB_PROVIDER=local
# DB_USER=your_db_user
# DB_PASSWORD=your_db_password
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=skyulf_mlops
# DB_SSLMODE=prefer
# DB_EXTRA_PARAMS=application_name=skyulf&connect_timeout=10
# DB_SSLROOTCERT=/path/to/ca-certificate.pem

# ====== LLM API Keys (Optional) ======
# OpenAI Configuration
# OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_MODEL=gpt-4
# OPENAI_TEMPERATURE=0.7
# OPENAI_MAX_TOKENS=2000

# Anthropic Claude Configuration
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
# ANTHROPIC_TEMPERATURE=0.7
# ANTHROPIC_MAX_TOKENS=2000

# DeepSeek Configuration
# DEEPSEEK_API_KEY=your-deepseek-api-key
# DEEPSEEK_BASE_URL=https://api.deepseek.com
# DEEPSEEK_MODEL=deepseek-chat
# DEEPSEEK_TEMPERATURE=0.7
# DEEPSEEK_MAX_TOKENS=2000

# Local LLM (Ollama) Configuration
# LOCAL_LLM_BASE_URL=http://localhost:11434
# LOCAL_LLM_MODEL=llama2

# ====== Redis Configuration (for Celery) ======
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1

# ====== Application Configuration ======
SECRET_KEY=replace-me-with-a-secure-secret-key-in-production
DEBUG=true
ALLOWED_HOSTS=localhost,127.0.0.1
# CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# ====== Logging ======
# LOG_LEVEL=INFO
# LOG_FILE=logs/skyulf.log

# ====== Security ======
# JWT_SECRET_KEY=your-jwt-secret-key-change-in-production
# JWT_ALGORITHM=HS256
# ACCESS_TOKEN_EXPIRE_MINUTES=60
