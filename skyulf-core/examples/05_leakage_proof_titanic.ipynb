{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ae27fe",
   "metadata": {},
   "source": [
    "# Proof of Trust: Preventing Data Leakage with Skyulf\n",
    "\n",
    "One of the biggest risks in Machine Learning is **Data Leakage**: when information from the test set (or the future) accidentally \"leaks\" into the training process. This creates models that look perfect during training but fail in production.\n",
    "\n",
    "Common sources of leakage:\n",
    "1.  **Imputation:** Filling missing values in the Test set using the mean of the *entire* dataset (including Test).\n",
    "2.  **Scaling:** Normalizing Test data using the min/max of the *entire* dataset.\n",
    "3.  **Target Encoding:** Encoding categorical features using the target mean of the *entire* dataset.\n",
    "\n",
    "## The Skyulf Guarantee\n",
    "Skyulf prevents this by design using the **Calculator / Applier** pattern.\n",
    "- **Calculator:** Learns statistics *only* from the Training data.\n",
    "- **Applier:** Applies those learned statistics to Test data blindly.\n",
    "\n",
    "This notebook proves this behavior using the **Titanic** dataset. We will:\n",
    "1.  Load the dataset.\n",
    "2.  Split it into Train/Test.\n",
    "3.  Run a Skyulf Pipeline.\n",
    "4.  **Mathematically verify** that the Test data was processed using *only* Training statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f7b2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Titanic dataset...\n",
      "Dataset Shape: (1309, 4)\n",
      "      sex      age      fare  survived\n",
      "0  female  29.0000  211.3375         1\n",
      "1    male   0.9167  151.5500         1\n",
      "2  female   2.0000  151.5500         0\n",
      "3    male  30.0000  151.5500         0\n",
      "4  female  25.0000  151.5500         0\n",
      "\n",
      "Missing Values:\n",
      " sex           0\n",
      "age         263\n",
      "fare          1\n",
      "survived      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure local skyulf-core is importable\n",
    "try:\n",
    "    import skyulf  # noqa: F401\n",
    "except ImportError:\n",
    "    here = Path.cwd()\n",
    "    candidates = [here, here / 'skyulf-core', here.parent, here.parent / 'skyulf-core']\n",
    "    for c in candidates:\n",
    "        if (c / 'skyulf' / '__init__.py').exists():\n",
    "            sys.path.insert(0, str(c))\n",
    "            break\n",
    "\n",
    "from skyulf import SkyulfPipeline\n",
    "from skyulf.data.dataset import SplitDataset\n",
    "\n",
    "# Load Titanic Dataset\n",
    "print(\"Loading Titanic dataset...\")\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
    "df = titanic.frame\n",
    "\n",
    "# Select relevant columns for demonstration\n",
    "# 'sex': Categorical (needs encoding)\n",
    "# 'age': Numeric with missing values (needs imputation)\n",
    "# 'fare': Numeric (needs scaling)\n",
    "# 'survived': Target\n",
    "cols = ['sex', 'age', 'fare', 'survived']\n",
    "df = df[cols].copy()\n",
    "\n",
    "# Convert target to int\n",
    "df['survived'] = df['survived'].astype(int)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(df.head())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50d9bb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (916, 4)\n",
      "Test Shape: (393, 4)\n"
     ]
    }
   ],
   "source": [
    "# 2. Split Data\n",
    "# We split BEFORE any processing to simulate a real-world scenario.\n",
    "X = df.drop(columns=['survived'])\n",
    "y = df['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create Skyulf Dataset\n",
    "dataset = SplitDataset(\n",
    "    train=pd.concat([X_train, y_train], axis=1),\n",
    "    test=pd.concat([X_test, y_test], axis=1)\n",
    ")\n",
    "\n",
    "print(f\"Train Shape: {dataset.train.shape}\")\n",
    "print(f\"Test Shape: {dataset.test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d73d6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline...\n",
      "Pipeline execution complete.\n"
     ]
    }
   ],
   "source": [
    "# 3. Define Pipeline\n",
    "# We intentionally use methods that are prone to leakage if done wrong.\n",
    "\n",
    "config = {\n",
    "    \"preprocessing\": [\n",
    "        # Imputation 1: Age (Train Mean)\n",
    "        {\n",
    "            \"name\": \"impute_age\",\n",
    "            \"transformer\": \"SimpleImputer\",\n",
    "            \"params\": {\"strategy\": \"mean\", \"columns\": [\"age\"]}\n",
    "        },\n",
    "        # Imputation 2: Fare (Train Mean) - Added for robustness\n",
    "        {\n",
    "            \"name\": \"impute_fare\",\n",
    "            \"transformer\": \"SimpleImputer\",\n",
    "            \"params\": {\"strategy\": \"mean\", \"columns\": [\"fare\"]}\n",
    "        },\n",
    "        # Scaling: Should use Train Mean/Std\n",
    "        {\n",
    "            \"name\": \"scale_fare\",\n",
    "            \"transformer\": \"StandardScaler\",\n",
    "            \"params\": {\"columns\": [\"fare\"]}\n",
    "        },\n",
    "        # Target Encoding: Should use Train Target Mean\n",
    "        # This is the most dangerous one! If it sees Test target, it's 100% leakage.\n",
    "        {\n",
    "            \"name\": \"encode_sex\",\n",
    "            \"transformer\": \"TargetEncoder\",\n",
    "            \"params\": {\"columns\": [\"sex\"], \"target_column\": \"survived\"}\n",
    "        }\n",
    "    ],\n",
    "    \"modeling\": {\n",
    "        \"type\": \"random_forest_classifier\",\n",
    "        \"params\": {\"n_estimators\": 10, \"random_state\": 42}\n",
    "    }\n",
    "}\n",
    "\n",
    "pipeline = SkyulfPipeline(config)\n",
    "\n",
    "# Fit the pipeline\n",
    "# This runs fit() on Train and transform() on Test\n",
    "print(\"Running pipeline...\")\n",
    "metrics = pipeline.fit(dataset, target_column=\"survived\")\n",
    "print(\"Pipeline execution complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "924e6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Age Mean: 29.1023\n",
      "Imputer Learned Mean: 29.1023\n",
      "Full Dataset Age Mean: 29.8811\n",
      "âœ… Imputation Sanity Check Passed: Learned mean differs from Full Dataset mean.\n",
      "âœ… Imputation Proof: The imputer learned the mean ONLY from the Training set.\n"
     ]
    }
   ],
   "source": [
    "# Get the fitted imputer from the pipeline\n",
    "imputer_step = pipeline.feature_engineer.fitted_steps[0]\n",
    "assert imputer_step['name'] == 'impute_age'\n",
    "\n",
    "# The fitted transformer is stored in 'artifact'\n",
    "artifact = imputer_step['artifact']\n",
    "fill_values = artifact['fill_values']\n",
    "\n",
    "# Calculate Train Mean manually\n",
    "train_age_mean = X_train['age'].mean()\n",
    "print(f\"Train Age Mean: {train_age_mean:.4f}\")\n",
    "\n",
    "# Check what the imputer learned\n",
    "learned_mean = fill_values['age']\n",
    "print(f\"Imputer Learned Mean: {learned_mean:.4f}\")\n",
    "\n",
    "# Verify\n",
    "np.testing.assert_allclose(train_age_mean, learned_mean)\n",
    "\n",
    "# --- NEW: Explicitly check against Full Dataset Mean ---\n",
    "full_age_mean = df['age'].mean()\n",
    "print(f\"Full Dataset Age Mean: {full_age_mean:.4f}\")\n",
    "\n",
    "# Assert that learned mean is NOT the full mean (additional sanity check)\n",
    "# Note: In some datasets, train mean could equal full mean by chance.\n",
    "if abs(learned_mean - full_age_mean) > 1e-4:\n",
    "    print(\"âœ… Imputation Sanity Check Passed: Learned mean differs from Full Dataset mean.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: Train mean equals Full mean (could be chance, but check split).\")\n",
    "\n",
    "print(\"âœ… Imputation Proof: The imputer learned the mean ONLY from the Training set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82c3aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fare Mean: 33.7092, Std: 52.7829\n",
      "Scaler Learned Mean: 33.7092, Scale: 52.7829\n",
      "Full Dataset Fare Mean: 33.2955, Std: 51.7389\n",
      "âœ… Scaling Mean Sanity Check Passed: Learned mean differs from Full Dataset mean.\n",
      "âœ… Scaling Std Sanity Check Passed: Learned std differs from Full Dataset std.\n",
      "âœ… Scaling Proof: The scaler learned stats ONLY from the Training set.\n"
     ]
    }
   ],
   "source": [
    "# Note: Index is 2 because we added impute_fare at index 1\n",
    "scaler_step = pipeline.feature_engineer.fitted_steps[2]\n",
    "assert scaler_step['name'] == 'scale_fare'\n",
    "\n",
    "artifact = scaler_step['artifact']\n",
    "\n",
    "# Calculate Train Stats manually (Exact)\n",
    "# We must use the imputed fare for manual calculation to match the pipeline's flow.\n",
    "train_fare_imputed = X_train[\"fare\"].fillna(X_train[\"fare\"].mean())\n",
    "train_fare_mean = train_fare_imputed.mean()\n",
    "train_fare_std  = train_fare_imputed.std(ddof=0) # Sklearn uses ddof=0 for std\n",
    "\n",
    "print(f\"Train Fare Mean: {train_fare_mean:.4f}, Std: {train_fare_std:.4f}\")\n",
    "\n",
    "# Check what the scaler learned\n",
    "columns = artifact['columns']\n",
    "fare_idx = columns.index('fare')\n",
    "\n",
    "learned_mean = artifact['mean'][fare_idx]\n",
    "learned_scale = artifact['scale'][fare_idx]\n",
    "print(f\"Scaler Learned Mean: {learned_mean:.4f}, Scale: {learned_scale:.4f}\")\n",
    "\n",
    "# Verify (Tight tolerance now possible)\n",
    "np.testing.assert_allclose(train_fare_mean, learned_mean)\n",
    "np.testing.assert_allclose(train_fare_std, learned_scale)\n",
    "\n",
    "# --- NEW: Explicitly check against Full Dataset Stats ---\n",
    "full_fare_mean = df['fare'].mean()\n",
    "full_fare_std = df['fare'].std(ddof=0)\n",
    "print(f\"Full Dataset Fare Mean: {full_fare_mean:.4f}, Std: {full_fare_std:.4f}\")\n",
    "\n",
    "# Additional Sanity Checks\n",
    "if abs(learned_mean - full_fare_mean) > 1e-4:\n",
    "    print(\"âœ… Scaling Mean Sanity Check Passed: Learned mean differs from Full Dataset mean.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: Train mean equals Full mean.\")\n",
    "\n",
    "if abs(learned_scale - full_fare_std) > 1e-4:\n",
    "    print(\"âœ… Scaling Std Sanity Check Passed: Learned std differs from Full Dataset std.\")\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: Train std equals Full std.\")\n",
    "\n",
    "print(\"âœ… Scaling Proof: The scaler learned stats ONLY from the Training set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b21e2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Target Means:\n",
      " sex\n",
      "female    0.694444\n",
      "male      0.179054\n",
      "Name: survived, dtype: float64\n",
      "\n",
      "Encoder Learned Means:\n",
      "  female: 0.693502\n",
      "  male: 0.179250\n",
      "\n",
      "Full Dataset Means (Leakage!):\n",
      " sex\n",
      "female    0.727468\n",
      "male      0.190985\n",
      "Name: survived, dtype: float64\n",
      "\n",
      "Comparison for 'male':\n",
      "  Train Mean: 0.179054\n",
      "  Full Mean:  0.190985\n",
      "  Encoded:    0.179250\n",
      "âœ… Target Encoding Proof: The encoder did NOT use the full dataset statistics.\n"
     ]
    }
   ],
   "source": [
    "# Note: Index is 3\n",
    "encoder_step = pipeline.feature_engineer.fitted_steps[3]\n",
    "assert encoder_step['name'] == 'encode_sex'\n",
    "\n",
    "artifact = encoder_step['artifact']\n",
    "encoder = artifact['encoder_object']\n",
    "\n",
    "# Calculate Train Target Mean for 'sex' manually\n",
    "train_sex_means = pd.concat([X_train, y_train], axis=1).groupby('sex', observed=True)['survived'].mean()\n",
    "print(\"Train Target Means:\\n\", train_sex_means)\n",
    "\n",
    "# Check what the encoder learned\n",
    "categories = encoder.categories_[0]\n",
    "encodings = encoder.encodings_[0]\n",
    "\n",
    "print(\"\\nEncoder Learned Means:\")\n",
    "for cat, enc in zip(categories, encodings):\n",
    "    print(f\"  {cat}: {enc:.6f}\")\n",
    "\n",
    "# Verify\n",
    "# Note: Sklearn's TargetEncoder uses cross-fitting and shrinkage (smoothing), \n",
    "# so the learned encodings will NOT equal the raw conditional means of the training set.\n",
    "# However, they must be **invariant** to changes in the Test set.\n",
    "\n",
    "full_sex_means = pd.concat([X, y], axis=1).groupby('sex', observed=True)['survived'].mean()\n",
    "print(\"\\nFull Dataset Means (Leakage!):\\n\", full_sex_means)\n",
    "\n",
    "# Check 'male'\n",
    "male_train_mean = train_sex_means['male']\n",
    "male_full_mean = full_sex_means['male']\n",
    "male_encoded = encodings[list(categories).index('male')]\n",
    "\n",
    "print(f\"\\nComparison for 'male':\")\n",
    "print(f\"  Train Mean: {male_train_mean:.6f}\")\n",
    "print(f\"  Full Mean:  {male_full_mean:.6f}\")\n",
    "print(f\"  Encoded:    {male_encoded:.6f}\")\n",
    "\n",
    "assert abs(male_encoded - male_full_mean) > 1e-4, \"Leakage detected! Encoded value matches Full Mean.\"\n",
    "print(\"âœ… Target Encoding Proof: The encoder did NOT use the full dataset statistics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ec40e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned Test Stats:\n",
      "  Age Mean: 10000.00\n",
      "  Fare Mean: 1000000.00\n",
      "  Target Mean: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Create a Poisoned Dataset\n",
    "# We keep Train exactly the same, but corrupt Test.\n",
    "X_test_poisoned = X_test.copy()\n",
    "y_test_poisoned = y_test.copy()\n",
    "\n",
    "# 1. Poison 'age' (Imputation)\n",
    "# Set all test ages to a massive number. If leakage exists, the mean will skyrocket.\n",
    "X_test_poisoned['age'] = 10000.0 \n",
    "\n",
    "# 2. Poison 'fare' (Scaling)\n",
    "# Set all test fares to a massive number.\n",
    "X_test_poisoned['fare'] = 1000000.0 \n",
    "\n",
    "# 3. Poison 'survived' (Target Encoding)\n",
    "# Flip all labels: 0->1, 1->0. If leakage exists, encodings will flip.\n",
    "y_test_poisoned = 1 - y_test_poisoned\n",
    "\n",
    "# Create Skyulf Dataset with Poisoned Test\n",
    "dataset_poisoned = SplitDataset(\n",
    "    train=pd.concat([X_train, y_train], axis=1),\n",
    "    test=pd.concat([X_test_poisoned, y_test_poisoned], axis=1)\n",
    ")\n",
    "\n",
    "print(\"Poisoned Test Stats:\")\n",
    "print(f\"  Age Mean: {X_test_poisoned['age'].mean():.2f}\")\n",
    "print(f\"  Fare Mean: {X_test_poisoned['fare'].mean():.2f}\")\n",
    "print(f\"  Target Mean: {y_test_poisoned.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3ce5afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned Test Stats:\n",
      "  Age Mean: 10000.00\n",
      "  Fare Mean: 1000000.00\n",
      "  Target Mean: 0.57\n",
      "\n",
      "Running pipeline on Poisoned Dataset...\n",
      "\n",
      "Imputation Comparison:\n",
      "  Original: 29.1023\n",
      "  Poisoned: 29.1023\n",
      "âœ… Imputation is unaffected by Test data.\n",
      "\n",
      "Scaling Comparison:\n",
      "  Original Mean: 33.7092, Scale: 52.7829\n",
      "  Poisoned Mean: 33.7092, Scale: 52.7829\n",
      "âœ… Scaling is unaffected by Test data.\n",
      "\n",
      "Target Encoding Comparison (First 5 values):\n",
      "  Original: [0.69350186 0.17924998]\n",
      "  Poisoned: [0.69350186 0.17924998]\n",
      "âœ… Target Encoding is unaffected by Test labels.\n",
      "\n",
      "ðŸŽ‰ FINAL VERDICT: The pipeline is LEAKAGE-RESISTANT by design.\n"
     ]
    }
   ],
   "source": [
    "# Create a Poisoned Dataset\n",
    "# We keep Train exactly the same, but corrupt Test.\n",
    "X_test_poisoned = X_test.copy()\n",
    "y_test_poisoned = y_test.copy()\n",
    "\n",
    "# 1. Poison 'age' (Imputation)\n",
    "# Set all test ages to a massive number. If leakage exists, the mean will skyrocket.\n",
    "X_test_poisoned['age'] = 10000.0 \n",
    "\n",
    "# 2. Poison 'fare' (Scaling)\n",
    "# Set all test fares to a massive number.\n",
    "X_test_poisoned['fare'] = 1000000.0 \n",
    "\n",
    "# 3. Poison 'survived' (Target Encoding)\n",
    "# Flip all labels: 0->1, 1->0. If leakage exists, encodings will flip.\n",
    "y_test_poisoned = 1 - y_test_poisoned\n",
    "\n",
    "# Create Skyulf Dataset with Poisoned Test\n",
    "dataset_poisoned = SplitDataset(\n",
    "    train=pd.concat([X_train, y_train], axis=1),\n",
    "    test=pd.concat([X_test_poisoned, y_test_poisoned], axis=1)\n",
    ")\n",
    "\n",
    "print(\"Poisoned Test Stats:\")\n",
    "print(f\"  Age Mean: {X_test_poisoned['age'].mean():.2f}\")\n",
    "print(f\"  Fare Mean: {X_test_poisoned['fare'].mean():.2f}\")\n",
    "print(f\"  Target Mean: {y_test_poisoned.mean():.2f}\")\n",
    "\n",
    "# Run Pipeline on Poisoned Data\n",
    "pipeline_poisoned = SkyulfPipeline(config) # Same config\n",
    "print(\"\\nRunning pipeline on Poisoned Dataset...\")\n",
    "pipeline_poisoned.fit(dataset_poisoned, target_column=\"survived\")\n",
    "\n",
    "# Compare Artifacts\n",
    "\n",
    "# 1. Imputation (Age)\n",
    "original_age_mean = pipeline.feature_engineer.fitted_steps[0]['artifact']['fill_values']['age']\n",
    "poisoned_age_mean = pipeline_poisoned.feature_engineer.fitted_steps[0]['artifact']['fill_values']['age']\n",
    "\n",
    "print(f\"\\nImputation Comparison:\")\n",
    "print(f\"  Original: {original_age_mean:.4f}\")\n",
    "print(f\"  Poisoned: {poisoned_age_mean:.4f}\")\n",
    "np.testing.assert_allclose(original_age_mean, poisoned_age_mean)\n",
    "print(\"âœ… Imputation is unaffected by Test data.\")\n",
    "\n",
    "# 2. Scaling (Fare)\n",
    "# Note: Index is 2\n",
    "original_scaler = pipeline.feature_engineer.fitted_steps[2]['artifact']\n",
    "poisoned_scaler = pipeline_poisoned.feature_engineer.fitted_steps[2]['artifact']\n",
    "\n",
    "original_fare_mean = original_scaler['mean'][0] # fare is only col\n",
    "poisoned_fare_mean = poisoned_scaler['mean'][0]\n",
    "original_fare_scale = original_scaler['scale'][0]\n",
    "poisoned_fare_scale = poisoned_scaler['scale'][0]\n",
    "\n",
    "print(f\"\\nScaling Comparison:\")\n",
    "print(f\"  Original Mean: {original_fare_mean:.4f}, Scale: {original_fare_scale:.4f}\")\n",
    "print(f\"  Poisoned Mean: {poisoned_fare_mean:.4f}, Scale: {poisoned_fare_scale:.4f}\")\n",
    "\n",
    "np.testing.assert_allclose(original_fare_mean, poisoned_fare_mean)\n",
    "np.testing.assert_allclose(original_fare_scale, poisoned_fare_scale)\n",
    "print(\"âœ… Scaling is unaffected by Test data.\")\n",
    "\n",
    "# 3. Target Encoding\n",
    "# Note: Index is 3\n",
    "original_encodings = pipeline.feature_engineer.fitted_steps[3]['artifact']['encoder_object'].encodings_[0]\n",
    "poisoned_encodings = pipeline_poisoned.feature_engineer.fitted_steps[3]['artifact']['encoder_object'].encodings_[0]\n",
    "\n",
    "print(f\"\\nTarget Encoding Comparison (First 5 values):\")\n",
    "print(f\"  Original: {original_encodings[:5]}\")\n",
    "print(f\"  Poisoned: {poisoned_encodings[:5]}\")\n",
    "np.testing.assert_allclose(original_encodings, poisoned_encodings)\n",
    "print(\"âœ… Target Encoding is unaffected by Test labels.\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ FINAL VERDICT: The pipeline is LEAKAGE-RESISTANT by design.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c98d45",
   "metadata": {},
   "source": [
    "## 7. The Ultimate Test: The \"Poisoned\" Dataset\n",
    "\n",
    "To prove beyond doubt that the Test set is ignored during training, we will run an experiment:\n",
    "1.  Take the original dataset.\n",
    "2.  **\"Poison\" the Test set** with extreme outliers and flipped labels.\n",
    "3.  Train a **new pipeline** on this poisoned dataset.\n",
    "4.  Compare the learned parameters with the original pipeline.\n",
    "\n",
    "**Hypothesis:** If there is NO leakage, the learned parameters (Imputation Mean, Scaling Stats, Encodings) must be **identical** to the original run, because the Training set hasn't changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2d7c9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have mathematically verified that:\n",
    "1.  **Imputation** on Test data used the **Train Mean**.\n",
    "2.  **Scaling** on Test data used the **Train Mean/Std**.\n",
    "3.  **Target Encoding** on Test data used the **Train Target Mean**.\n",
    "\n",
    "This proves that **Skyulf pipelines are leakage-resistant by design**. The strict separation of `fit()` (Calculator) and `transform()` (Applier) ensures that no information from the Test set (or future data) can influence the model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
