{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8f682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Make sure the local Skyulf Core is importable whether this runs from repo root or from skyulf-core/\n",
    "try:\n",
    "    import skyulf  # noqa: F401\n",
    "except ImportError:\n",
    "    here = Path.cwd()\n",
    "    candidates = [here, here / 'skyulf-core', here.parent, here.parent / 'skyulf-core']\n",
    "    for c in candidates:\n",
    "        if (c / 'skyulf' / '__init__.py').exists():\n",
    "            sys.path.insert(0, str(c))\n",
    "            break\n",
    "\n",
    "from skyulf import SkyulfPipeline\n",
    "from skyulf.data.dataset import SplitDataset\n",
    "\n",
    "np.random.seed(42)\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0152a345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (426, 32) Test: (143, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>radius_band</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>19.89</td>\n",
       "      <td>20.26</td>\n",
       "      <td>130.50</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.13100</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.09431</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.06188</td>\n",
       "      <td>...</td>\n",
       "      <td>160.5</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.3309</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.16130</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.09136</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>87.4</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.14</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>...</td>\n",
       "      <td>152.4</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>17.30</td>\n",
       "      <td>17.08</td>\n",
       "      <td>113.00</td>\n",
       "      <td>928.2</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.10410</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.08353</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.05613</td>\n",
       "      <td>...</td>\n",
       "      <td>130.9</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>0.14160</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.3378</td>\n",
       "      <td>0.18570</td>\n",
       "      <td>0.3138</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>22.01</td>\n",
       "      <td>21.90</td>\n",
       "      <td>147.20</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.19540</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.15010</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.06140</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.3885</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.24320</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.08574</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "517        19.89         20.26          130.50     1214.0          0.10370   \n",
       "287        12.89         13.12           81.89      515.9          0.06955   \n",
       "25         17.14         16.40          116.00      912.7          0.11860   \n",
       "253        17.30         17.08          113.00      928.2          0.10080   \n",
       "369        22.01         21.90          147.20     1482.0          0.10630   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "517           0.13100          0.1411              0.09431         0.1802   \n",
       "287           0.03729          0.0226              0.01171         0.1337   \n",
       "25            0.22760          0.2229              0.14010         0.3040   \n",
       "253           0.10410          0.1266              0.08353         0.1813   \n",
       "369           0.19540          0.2448              0.15010         0.1824   \n",
       "\n",
       "     mean fractal dimension  ...  worst perimeter  worst area  \\\n",
       "517                 0.06188  ...            160.5      1646.0   \n",
       "287                 0.05581  ...             87.4       577.0   \n",
       "25                  0.07413  ...            152.4      1461.0   \n",
       "253                 0.05613  ...            130.9      1222.0   \n",
       "369                 0.06140  ...            195.0      2227.0   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "517           0.14170             0.3309           0.4185   \n",
       "287           0.09616             0.1147           0.1186   \n",
       "25            0.15450             0.3949           0.3853   \n",
       "253           0.14160             0.2405           0.3378   \n",
       "369           0.12940             0.3885           0.4756   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "517               0.16130          0.2549                  0.09136   \n",
       "287               0.05366          0.2309                  0.06915   \n",
       "25                0.25500          0.4066                  0.10590   \n",
       "253               0.18570          0.3138                  0.08113   \n",
       "369               0.24320          0.2741                  0.08574   \n",
       "\n",
       "     radius_band  label  \n",
       "517        large      0  \n",
       "287       medium      1  \n",
       "25         large      0  \n",
       "253        large      0  \n",
       "369        large      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataset with numeric + categorical features + missing values\n",
    "raw = load_breast_cancer(as_frame=True)\n",
    "df = raw.frame.copy()\n",
    "df = df.rename(columns={'target': 'label'})\n",
    "\n",
    "# Add a categorical feature derived from a numeric feature\n",
    "df['radius_band'] = pd.cut(\n",
    "    df['mean radius'],\n",
    "    bins=[0, 12, 15, 100],\n",
    "    labels=['small', 'medium', 'large'],\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Introduce missing values in a numeric column\n",
    "missing_idx = np.random.choice(df.index, size=25, replace=False)\n",
    "df.loc[missing_idx, 'mean texture'] = np.nan\n",
    "\n",
    "target_col = 'label'\n",
    "cat_cols = ['radius_band']\n",
    "num_cols = [c for c in df.columns if c not in [target_col, *cat_cols]]\n",
    "\n",
    "X = df[num_cols + cat_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df[target_col] = y_train\n",
    "test_df = X_test.copy()\n",
    "test_df[target_col] = y_test\n",
    "\n",
    "dataset = SplitDataset(train=train_df, test=test_df, validation=None)\n",
    "\n",
    "print('Train:', dataset.train.shape, 'Test:', dataset.test.shape)\n",
    "dataset.train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8387177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn test accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519    1\n",
       "408    0\n",
       "291    1\n",
       "518    1\n",
       "385    0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- scikit-learn baseline ---\n",
    "# Keep OneHotEncoder dense to mirror Skyulf's encoder output.\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:  # older scikit-learn\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "numeric = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', ohe),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric, num_cols),\n",
    "        ('cat', categorical, cat_cols),\n",
    "    ],\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "sk_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocess', preprocess),\n",
    "        ('model', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "sk_pipe.fit(X_train, y_train)\n",
    "sk_pred = pd.Series(sk_pipe.predict(X_test), index=X_test.index)\n",
    "\n",
    "sk_acc = accuracy_score(y_test, sk_pred)\n",
    "print(f'scikit-learn test accuracy: {sk_acc:.4f}')\n",
    "sk_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420fd984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skyulf test accuracy: 0.9790\n",
      "delta accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519    1\n",
       "408    0\n",
       "291    1\n",
       "518    1\n",
       "385    0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- SkyulfPipeline equivalent ---\n",
    "config = {\n",
    "    'preprocessing': [\n",
    "        {\n",
    "            'name': 'impute_numeric',\n",
    "            'transformer': 'SimpleImputer',\n",
    "            'params': {'strategy': 'mean', 'columns': num_cols},\n",
    "        },\n",
    "        {\n",
    "            'name': 'impute_categorical',\n",
    "            'transformer': 'SimpleImputer',\n",
    "            'params': {'strategy': 'most_frequent', 'columns': cat_cols},\n",
    "        },\n",
    "        {\n",
    "            'name': 'encode_categorical',\n",
    "            'transformer': 'OneHotEncoder',\n",
    "            'params': {'columns': cat_cols, 'drop_original': True, 'handle_unknown': 'ignore'},\n",
    "        },\n",
    "        {\n",
    "            'name': 'scale_numeric',\n",
    "            'transformer': 'StandardScaler',\n",
    "            'params': {'columns': num_cols},\n",
    "        },\n",
    "    ],\n",
    "    'modeling': {\n",
    "        'type': 'logistic_regression',\n",
    "        'node_id': 'model',\n",
    "        'params': {'max_iter': 1000, 'random_state': 42},\n",
    "    },\n",
    "}\n",
    "\n",
    "sky_pipe = SkyulfPipeline(config)\n",
    "metrics = sky_pipe.fit(dataset, target_column=target_col)\n",
    "\n",
    "sky_pred = sky_pipe.predict(X_test)\n",
    "sky_acc = accuracy_score(y_test, sky_pred)\n",
    "delta = abs(sk_acc - sky_acc)\n",
    "print(f'Skyulf test accuracy: {sky_acc:.4f}')\n",
    "print(f'delta accuracy: {delta:.4f}')\n",
    "\n",
    "# Basic correctness checks (style)\n",
    "assert isinstance(sky_pred, pd.Series)\n",
    "assert sky_pred.index.equals(X_test.index)\n",
    "assert sky_pred.isna().sum() == 0\n",
    "\n",
    "sky_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1af77fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report (side-by-side):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">sklearn</th>\n",
       "      <th colspan=\"4\" halign=\"left\">skyulf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.983240</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.983240</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.975864</td>\n",
       "      <td>0.979455</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>0.979455</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.979201</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979060</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.979201</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.979060</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sklearn                                    skyulf            \\\n",
       "             precision    recall  f1-score     support precision    recall   \n",
       "0             0.962963  0.981132  0.971963   53.000000  0.962963  0.981132   \n",
       "1             0.988764  0.977778  0.983240   90.000000  0.988764  0.977778   \n",
       "accuracy      0.979021  0.979021  0.979021    0.979021  0.979021  0.979021   \n",
       "macro avg     0.975864  0.979455  0.977601  143.000000  0.975864  0.979455   \n",
       "weighted avg  0.979201  0.979021  0.979060  143.000000  0.979201  0.979021   \n",
       "\n",
       "                                    \n",
       "              f1-score     support  \n",
       "0             0.971963   53.000000  \n",
       "1             0.983240   90.000000  \n",
       "accuracy      0.979021    0.979021  \n",
       "macro avg     0.977601  143.000000  \n",
       "weighted avg  0.979060  143.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (sklearn):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_1</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "true_0      52       1\n",
       "true_1       2      88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (skyulf):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_1</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1\n",
       "true_0      52       1\n",
       "true_1       2      88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Classification metrics: side-by-side ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Reports as dicts -> DataFrames for side-by-side comparison\n",
    "sk_report = classification_report(y_test, sk_pred, output_dict=True, zero_division=0)\n",
    "sky_report = classification_report(y_test, sky_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "sk_df = pd.DataFrame(sk_report).T\n",
    "sky_df = pd.DataFrame(sky_report).T\n",
    "\n",
    "# Keep a consistent row order: class labels first, then summary rows (if present)\n",
    "label_rows = [str(v) for v in sorted(pd.unique(y_test))]\n",
    "summary_rows = [r for r in ['accuracy', 'macro avg', 'weighted avg'] if r in sk_df.index]\n",
    "row_order = [r for r in label_rows if r in sk_df.index] + summary_rows\n",
    "\n",
    "sk_df = sk_df.loc[row_order]\n",
    "sky_df = sky_df.loc[row_order]\n",
    "\n",
    "side_by_side = pd.concat(\n",
    "    {\n",
    "        'sklearn': sk_df[['precision', 'recall', 'f1-score', 'support']],\n",
    "        'skyulf': sky_df[['precision', 'recall', 'f1-score', 'support']],\n",
    "    },\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print('Classification report (side-by-side):')\n",
    "display(side_by_side)\n",
    "\n",
    "# Confusion matrices\n",
    "labels = sorted(pd.unique(y_test))\n",
    "cm_sk = confusion_matrix(y_test, sk_pred, labels=labels)\n",
    "cm_sky = confusion_matrix(y_test, sky_pred, labels=labels)\n",
    "\n",
    "cm_index = [f'true_{l}' for l in labels]\n",
    "cm_cols = [f'pred_{l}' for l in labels]\n",
    "\n",
    "cm_sk_df = pd.DataFrame(cm_sk, index=cm_index, columns=cm_cols)\n",
    "cm_sky_df = pd.DataFrame(cm_sky, index=cm_index, columns=cm_cols)\n",
    "\n",
    "print('Confusion matrix (sklearn):')\n",
    "display(cm_sk_df)\n",
    "print('Confusion matrix (skyulf):')\n",
    "display(cm_sky_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3441adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions match exactly.\n"
     ]
    }
   ],
   "source": [
    "assert (sk_pred.values == sky_pred.values).all()\n",
    "print(\"Predictions match exactly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71735e81",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This notebook does **not** claim the two models will produce identical predictions; they are different implementations and may differ in preprocessing details.\n",
    "- The goal is to demonstrate a familiar workflow and validate basic invariants (shapes/index alignment, no NaNs, runnable end-to-end)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
