# Quick Start: Implementing Automatic Split Detection

## For Developers: 3-Step Implementation

### Step 1: Import the Split Handler (30 seconds)

Add to your `routes.py`:

```python
from core.feature_engineering.split_handler import (
    detect_splits,
    log_split_processing,
    remove_split_column,
)
```

### Step 2: Add Split Detection to Pipeline Loop (2 minutes)

In your pipeline execution function, add split detection:

```python
def execute_pipeline(nodes, edges, working_frame, pipeline_id=None):
    applied_steps = []
    
    for node in nodes:
        node_id = node.get("id")
        catalog_type = node.get("data", {}).get("catalogType", "")
        
        # ADD THIS: Detect and log splits
        split_info = detect_splits(working_frame)
        log_split_processing(node_id, catalog_type, split_info)
        
        # Your existing node processing code stays the same!
        if catalog_type == "scale_numeric_features":
            working_frame, summary, signal = apply_scale_numeric_features(
                working_frame, node, pipeline_id=pipeline_id
            )
        # ... rest of your nodes
        
        applied_steps.append(summary)
    
    # ADD THIS: Remove internal split column before returning
    final_frame = remove_split_column(working_frame)
    
    return final_frame, applied_steps
```

### Step 3: Enjoy Automatic Split Handling (0 minutes)

That's it! Your nodes now automatically:
- âœ… Detect train/test/validation splits
- âœ… Fit transformers on train only
- âœ… Transform all splits appropriately
- âœ… Process filters independently per split
- âœ… Apply resampling to train only
- âœ… Log all split operations
- âœ… Prevent data leakage

## For Users: How It Works

### Creating Splits

Use the **Train/Test Split** node in your workflow:

1. Add **Train/Test Split** node to canvas
2. Configure split ratios:
   - Test size: 0.2 (20%)
   - Validation size: 0.1 (10%) - optional
   - Random state: 42
3. Connect to your dataset

### What Happens Next

**All downstream nodes automatically detect and handle splits:**

#### Transformers (Scalers, Encoders, Imputers)
- Fit on **training data only** â† Prevents data leakage!
- Transform **all splits** (train, test, validation)
- Example: StandardScaler learns mean/std from train, applies to all

#### Filters (Remove Duplicates, Drop Nulls, Outlier Removal)
- Process **each split independently**
- Train duplicates don't affect test
- Example: Remove duplicates separately in train and test

#### Resampling (SMOTE, Undersampling)
- Apply **only to training data** â† Prevents data leakage!
- Test and validation unchanged
- Example: SMOTE creates synthetic samples in train only

#### Models (Training, Prediction)
- Train on **training data**
- Predict on **test/validation data**
- Example: RandomForest fits on train, predicts on test

### Visual Example

```
Dataset (1000 rows)
    â†“
Train/Test Split (70/20/10)
    â†“
â”œâ”€ Train: 700 rows
â”œâ”€ Test: 200 rows
â””â”€ Validation: 100 rows
    â†“
StandardScaler Node
    â”œâ”€ FIT on train (700 rows) â†’ learns Î¼=50, Ïƒ=10
    â”œâ”€ TRANSFORM train (700 rows) using Î¼=50, Ïƒ=10
    â”œâ”€ TRANSFORM test (200 rows) using Î¼=50, Ïƒ=10  â† No leakage!
    â””â”€ TRANSFORM validation (100 rows) using Î¼=50, Ïƒ=10  â† No leakage!
    â†“
Remove Duplicates Node
    â”œâ”€ Process train (700 â†’ 680 rows)
    â”œâ”€ Process test (200 â†’ 195 rows)
    â””â”€ Process validation (100 â†’ 98 rows)
    â†“
SMOTE Oversampling Node
    â”œâ”€ Apply to train (680 â†’ 900 rows)  â† Balanced classes
    â”œâ”€ Test unchanged (195 rows)  â† No synthetic samples!
    â””â”€ Validation unchanged (98 rows)  â† No synthetic samples!
    â†“
Model Training Node
    â”œâ”€ Train on train (900 rows)
    â”œâ”€ Predict on test (195 rows)
    â””â”€ Predict on validation (98 rows)
```

## Benefits for You

### Before (Manual Split Handling)
```
âŒ Needed to remember which nodes to apply to which split
âŒ Easy to accidentally cause data leakage
âŒ Had to manually configure each node
âŒ Complex to track what happened where
âŒ Errors were common
```

### After (Automatic Split Detection)
```
âœ… Splits detected automatically
âœ… Data leakage prevented automatically
âœ… No manual configuration needed
âœ… Clear logs show what happened
âœ… Just works!
```

## Common Workflows

### Workflow 1: Basic Classification
```
1. Upload Dataset
2. Train/Test Split (80/20)
3. StandardScaler â†’ Auto: fit on train, transform both
4. One-Hot Encoding â†’ Auto: fit on train, transform both
5. Train Model â†’ Auto: fit on train, predict on test
```

### Workflow 2: Imbalanced Classes
```
1. Upload Dataset
2. Train/Test Split (70/30)
3. SMOTE Oversampling â†’ Auto: only on train!
4. StandardScaler â†’ Auto: fit on train, transform both
5. Train Model â†’ Auto: fit on train, predict on test
```

### Workflow 3: With Validation Set
```
1. Upload Dataset
2. Train/Test/Validation Split (70/20/10)
3. StandardScaler â†’ Auto: fit on train, transform all 3
4. Feature Engineering â†’ Auto: fit on train, transform all 3
5. Train Model â†’ Auto: fit on train, predict on test + validation
```

## Monitoring

### Check Split Information

The system automatically logs:
```
INFO: Node scaler-1 (scale_numeric_features): processing with splits 
      [train=700, test=200, validation=100] - Category: transformer
INFO: âœ“ Fitted scaler on 700 train rows
INFO: âœ“ Transformed 1000 total rows (train + test + validation)
```

### In the UI

Split information is shown:
- Node status shows "Processing train split..." 
- Results show split-aware summaries
- Transformer Audit Report shows fit/transform per split

## Troubleshooting

### Q: My node isn't detecting splits
**A:** Check that:
1. Train/Test Split node is connected upstream
2. Pipeline execution is sequential
3. Logs show "No splits detected" â†’ Check connections

### Q: How do I know if it's working?
**A:** Look for logs like:
- "processing with splits [train=X, test=Y]"
- "Fitted on X train rows"
- "Transformed Y total rows"

### Q: Can I disable it for a specific node?
**A:** Yes, the node will process normally if no splits are detected.
Just don't connect it downstream of a split node.

### Q: What if I want manual control?
**A:** You can still manually configure nodes. The automatic detection
enhances the system but doesn't restrict manual control.

## Next Steps

1. âœ… Try the Train/Test Split node
2. âœ… Add a StandardScaler downstream
3. âœ… Check the logs to see automatic split handling
4. âœ… Review the Transformer Audit Report
5. âœ… Build your ML pipeline!

## Summary

**Old Way:**
- ğŸ¤” "Did I apply the scaler correctly?"
- ğŸ¤” "Is there data leakage?"
- ğŸ¤” "Which split is this?"
- ğŸ˜° Manual configuration everywhere

**New Way:**
- âœ… Automatic split detection
- âœ… Zero data leakage
- âœ… Clear split tracking
- ğŸ˜Š Just works!

**You now have enterprise-grade split handling with zero extra effort!** ğŸš€
