{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4130ca8",
   "metadata": {},
   "source": [
    "# Skyulf Core: Low-Level Component Example\n",
    "\n",
    "This notebook demonstrates the **\"Component Way\"** of using Skyulf. \n",
    "Instead of a single `SkyulfPipeline` wrapper, we will manually:\n",
    "1.  Split the data.\n",
    "2.  Use `FeatureEngineer` component directly to fit and transform.\n",
    "3.  Use the `SklearnCalculator` / `SklearnApplier` components directly for modeling.\n",
    "\n",
    "This approach gives you maximum flexibility for debugging or custom workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a602f55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded.\n",
      "   Survived  Pclass     Sex   Age     Fare Embarked\n",
      "0         0       3    male  22.0   7.2500        S\n",
      "1         1       1  female  38.0  71.2833        C\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Skyulf Low-Level Components\n",
    "from skyulf.preprocessing.pipeline import FeatureEngineer\n",
    "from skyulf.modeling.classification import RandomForestClassifierCalculator, RandomForestClassifierApplier\n",
    "\n",
    "# 1. Load Data\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\n",
    "\n",
    "print(\"Data Loaded.\")\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3e7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (712, 5)\n",
      "Test Shape: (179, 5)\n"
     ]
    }
   ],
   "source": [
    "# 2. Manual Data Separation & Splitting\n",
    "# Since we aren't using the integrated pipeline, we must split X and y manually.\n",
    "\n",
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Test Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595bedaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineer Initialized.\n"
     ]
    }
   ],
   "source": [
    "# 3. Initialize Feature Engineer\n",
    "# We define the steps list exactly as we did in the pipeline, \n",
    "# but now we feed it into the FeatureEngineer class directly.\n",
    "\n",
    "fe_steps = [\n",
    "    {\n",
    "        \"name\": \"imputer_age\",\n",
    "        \"transformer\": \"SimpleImputer\", \n",
    "        \"params\": {\"columns\": [\"Age\"], \"strategy\": \"mean\"}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"imputer_embarked\",\n",
    "        \"transformer\": \"SimpleImputer\",\n",
    "        \"params\": {\"columns\": [\"Embarked\"], \"strategy\": \"most_frequent\"}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"encoder\",\n",
    "        \"transformer\": \"OneHotEncoder\",\n",
    "        \"params\": {\"columns\": [\"Sex\", \"Embarked\"], \"drop_first\": False}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"scaler\",\n",
    "        \"transformer\": \"StandardScaler\",\n",
    "        \"params\": {\"columns\": [\"Age\", \"Fare\"]}\n",
    "    }\n",
    "]\n",
    "\n",
    "feature_engineer = FeatureEngineer(fe_steps)\n",
    "\n",
    "print(\"Feature Engineer Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0910f5",
   "metadata": {},
   "source": [
    "# 3b. Deep Dive: The Atomic \"Calculator-Applier\" Pattern\n",
    "Before running the full `FeatureEngineer`, let's demonstrate what happens **inside** it for a single step (e.g., Age Imputation).\n",
    "This is the \"Ultra Low-Level\" API: using individual Calculator and Applier classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f03c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸ”¬ Atomic Execution Loop (The 'Under the Hood' View) ---\n",
      "\n",
      "[Step: imputer_age] Type: SimpleImputer\n",
      "  â”œâ”€â”€ Calculator: SimpleImputerCalculator\n",
      "  â”œâ”€â”€ Config (Input params): {\n",
      "  \"columns\": [\n",
      "    \"Age\"\n",
      "  ],\n",
      "  \"strategy\": \"mean\"\n",
      "}\n",
      "  â”œâ”€â”€ Fitted Artifact (Learned State): \n",
      "{\n",
      "    \"type\": \"simple_imputer\",\n",
      "    \"strategy\": \"mean\",\n",
      "    \"fill_values\": {\n",
      "        \"Pclass\": 2.330056179775281,\n",
      "        \"Age\": 29.498846153846156,\n",
      "        \"Fare\": 32.5862761235955\n",
      "    },\n",
      "    \"columns\": [\n",
      "        \"Pclass\",\n",
      "        \"Age\",\n",
      "        \"Fare\"\n",
      "    ],\n",
      "    \"missing_counts\": {\n",
      "        \"Pclass\": 0,\n",
      "        \"Age\": 140,\n",
      "        \"Fare\": 0\n",
      "    },\n",
      "    \"total_missing\": 140\n",
      "}\n",
      "  â”œâ”€â”€ Applier: SimpleImputerApplier\n",
      "  â””â”€â”€ Output Shape: (712, 5)\n",
      "\n",
      "[Step: imputer_embarked] Type: SimpleImputer\n",
      "  â”œâ”€â”€ Calculator: SimpleImputerCalculator\n",
      "  â”œâ”€â”€ Config (Input params): {\n",
      "  \"columns\": [\n",
      "    \"Embarked\"\n",
      "  ],\n",
      "  \"strategy\": \"most_frequent\"\n",
      "}\n",
      "  â”œâ”€â”€ Fitted Artifact (Learned State): \n",
      "{\n",
      "    \"type\": \"simple_imputer\",\n",
      "    \"strategy\": \"mean\",\n",
      "    \"fill_values\": {\n",
      "        \"Pclass\": 2.330056179775281,\n",
      "        \"Age\": 29.498846153846152,\n",
      "        \"Fare\": 32.5862761235955\n",
      "    },\n",
      "    \"columns\": [\n",
      "        \"Pclass\",\n",
      "        \"Age\",\n",
      "        \"Fare\"\n",
      "    ],\n",
      "    \"missing_counts\": {\n",
      "        \"Pclass\": 0,\n",
      "        \"Age\": 0,\n",
      "        \"Fare\": 0\n",
      "    },\n",
      "    \"total_missing\": 0\n",
      "}\n",
      "  â”œâ”€â”€ Applier: SimpleImputerApplier\n",
      "  â””â”€â”€ Output Shape: (712, 5)\n",
      "\n",
      "[Step: encoder] Type: OneHotEncoder\n",
      "  â”œâ”€â”€ Calculator: OneHotEncoderCalculator\n",
      "  â”œâ”€â”€ Config (Input params): {\n",
      "  \"columns\": [\n",
      "    \"Sex\",\n",
      "    \"Embarked\"\n",
      "  ],\n",
      "  \"drop_first\": false\n",
      "}\n",
      "  â”œâ”€â”€ Fitted Artifact (Learned State): \n",
      "{\n",
      "    \"type\": \"onehot\",\n",
      "    \"columns\": [\n",
      "        \"Sex\",\n",
      "        \"Embarked\"\n",
      "    ],\n",
      "    \"feature_names\": [\n",
      "        \"Sex_female\",\n",
      "        \"Sex_male\",\n",
      "        \"Embarked_C\",\n",
      "        \"Embarked_Q\",\n",
      "        \"Embarked_S\",\n",
      "        \"Embarked_nan\"\n",
      "    ],\n",
      "    \"prefix_separator\": \"_\",\n",
      "    \"drop_original\": true,\n",
      "    \"include_missing\": false,\n",
      "    \"encoder_object\": \"<Binary Scikit-Learn Object>\"\n",
      "}\n",
      "  â”œâ”€â”€ Applier: OneHotEncoderApplier\n",
      "  â””â”€â”€ Output Shape: (712, 9)\n",
      "\n",
      "[Step: scaler] Type: StandardScaler\n",
      "  â”œâ”€â”€ Calculator: StandardScalerCalculator\n",
      "  â”œâ”€â”€ Config (Input params): {\n",
      "  \"columns\": [\n",
      "    \"Age\",\n",
      "    \"Fare\"\n",
      "  ]\n",
      "}\n",
      "  â”œâ”€â”€ Fitted Artifact (Learned State): \n",
      "{\n",
      "    \"type\": \"standard_scaler\",\n",
      "    \"mean\": [\n",
      "        2.330056179775281,\n",
      "        29.498846153846152,\n",
      "        32.5862761235955\n",
      "    ],\n",
      "    \"scale\": [\n",
      "        0.8240050160689278,\n",
      "        12.985175473457835,\n",
      "        51.93302107304959\n",
      "    ],\n",
      "    \"var\": [\n",
      "        0.678984266506754,\n",
      "        168.6147820764909,\n",
      "        2697.038677773812\n",
      "    ],\n",
      "    \"with_mean\": true,\n",
      "    \"with_std\": true,\n",
      "    \"columns\": [\n",
      "        \"Pclass\",\n",
      "        \"Age\",\n",
      "        \"Fare\"\n",
      "    ]\n",
      "}\n",
      "  â”œâ”€â”€ Applier: StandardScalerApplier\n",
      "  â””â”€â”€ Output Shape: (712, 9)\n",
      "\n",
      "--- âœ… Final Transformed Data (Matching FeatureEngineer Output) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-1.614136</td>\n",
       "      <td>1.232263</td>\n",
       "      <td>-0.078684</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>-0.400551</td>\n",
       "      <td>-0.500482</td>\n",
       "      <td>-0.377145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.813034</td>\n",
       "      <td>0.192616</td>\n",
       "      <td>-0.474867</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.813034</td>\n",
       "      <td>-0.269449</td>\n",
       "      <td>-0.476230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.813034</td>\n",
       "      <td>-1.809667</td>\n",
       "      <td>-0.025249</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pclass       Age      Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "331 -1.614136  1.232263 -0.078684           0         1           0   \n",
       "733 -0.400551 -0.500482 -0.377145           0         1           0   \n",
       "382  0.813034  0.192616 -0.474867           0         1           0   \n",
       "704  0.813034 -0.269449 -0.476230           0         1           0   \n",
       "813  0.813034 -1.809667 -0.025249           1         0           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  Embarked_nan  \n",
       "331           0           1             0  \n",
       "733           0           1             0  \n",
       "382           0           1             0  \n",
       "704           0           1             0  \n",
       "813           0           1             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skyulf.preprocessing.imputation import SimpleImputerCalculator, SimpleImputerApplier\n",
    "from skyulf.preprocessing.encoding import OneHotEncoderCalculator, OneHotEncoderApplier\n",
    "from skyulf.preprocessing.scaling import StandardScalerCalculator, StandardScalerApplier\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Define a mapping from string names to actual implementation classes\n",
    "# In the real Skyulf backend, this is handled by a sophisticated Registry\n",
    "component_map = {\n",
    "    \"SimpleImputer\": (SimpleImputerCalculator, SimpleImputerApplier),\n",
    "    \"OneHotEncoder\": (OneHotEncoderCalculator, OneHotEncoderApplier),\n",
    "    \"StandardScaler\": (StandardScalerCalculator, StandardScalerApplier)\n",
    "}\n",
    "\n",
    "# Helper to serialize numpy types for display\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "print(\"--- ðŸ”¬ Atomic Execution Loop (The 'Under the Hood' View) ---\")\n",
    "\n",
    "# We start with a copy of X_train so we don't affect other cells\n",
    "X_current = X_train.copy()\n",
    "\n",
    "for step in fe_steps:\n",
    "    step_name = step[\"name\"]\n",
    "    transformer_type = step[\"transformer\"]\n",
    "    params = step[\"params\"]\n",
    "    \n",
    "    print(f\"\\n[Step: {step_name}] Type: {transformer_type}\")\n",
    "    \n",
    "    # 1. Resolve Components\n",
    "    CalculatorCls, ApplierCls = component_map[transformer_type]\n",
    "    \n",
    "    # 2. Instantiate Calculator & Fit\n",
    "    # The SDK expects a config dictionary wrapping the params\n",
    "    step_config = {\"params\": params}\n",
    "    \n",
    "    calculator = CalculatorCls()\n",
    "    # .fit() creates the portable artifact (state)\n",
    "    fitted_artifact = calculator.fit(X_current, step_config)\n",
    "    \n",
    "    print(f\"  â”œâ”€â”€ Calculator: {calculator.__class__.__name__}\")\n",
    "    print(f\"  â”œâ”€â”€ Config (Input params): {json.dumps(params, indent=2)}\")\n",
    "    \n",
    "    # Clean up artifact display (remove binary objects if any usually encoding has objects)\n",
    "    display_artifact = {k: v for k, v in fitted_artifact.items() if k != 'encoder_object'}\n",
    "    if 'encoder_object' in fitted_artifact:\n",
    "        display_artifact['encoder_object'] = \"<Binary Scikit-Learn Object>\"\n",
    "        \n",
    "    print(f\"  â”œâ”€â”€ Fitted Artifact (Learned State): \\n{json.dumps(display_artifact, cls=NumpyEncoder, indent=4)}\")\n",
    "    \n",
    "    # 3. Instantiate Applier & Apply\n",
    "    applier = ApplierCls()\n",
    "    # .apply() takes data + the artifact from the calculator\n",
    "    X_current = applier.apply(X_current, fitted_artifact)\n",
    "    \n",
    "    print(f\"  â”œâ”€â”€ Applier: {applier.__class__.__name__}\")\n",
    "    print(f\"  â””â”€â”€ Output Shape: {X_current.shape}\")\n",
    "\n",
    "print(\"\\n--- âœ… Final Transformed Data (Matching FeatureEngineer Output) ---\")\n",
    "display(X_current.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4a2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Feature Engineer on Train Data...\n",
      "Transforming Test Data (using learned params)...\n",
      "\n",
      "Transformed Train Shape: (712, 8)\n",
      "Transformed Test Shape: (179, 8)\n",
      "\n",
      "Sample Transformed Data:\n",
      "     Pclass       Age      Fare  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
      "331       1  1.232263 -0.078684           0         1           0           0   \n",
      "733       2 -0.500482 -0.377145           0         1           0           0   \n",
      "382       3  0.192616 -0.474867           0         1           0           0   \n",
      "\n",
      "     Embarked_S  \n",
      "331           1  \n",
      "733           1  \n",
      "382           1  \n"
     ]
    }
   ],
   "source": [
    "# 4. Fit & Transform Features\n",
    "# We call fit_transform on training data.\n",
    "# This learns the means/categories AND applies them to X_train.\n",
    "\n",
    "# Note: Skyulf's FeatureEngineer returns (transformed_data, metrics)\n",
    "print(\"Fitting Feature Engineer on Train Data...\")\n",
    "X_train_transformed, metrics = feature_engineer.fit_transform(X_train)\n",
    "\n",
    "# Now we apply the learned transformations to Test Data\n",
    "print(\"Transforming Test Data (using learned params)...\")\n",
    "X_test_transformed = feature_engineer.transform(X_test)\n",
    "\n",
    "print(\"\\nTransformed Train Shape:\", X_train_transformed.shape)\n",
    "print(\"Transformed Test Shape:\", X_test_transformed.shape)\n",
    "print(\"\\nSample Transformed Data:\")\n",
    "print(X_train_transformed.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c39f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model Calculator...\n",
      "\n",
      "Model Artifact Type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "RandomForestClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=5,\n",
      "                       n_estimators=50, n_jobs=-1, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# 5. Fit Model (Calculator)\n",
    "# Now we manually fit the Random Forest Calculator.\n",
    "\n",
    "rf_config = {\n",
    "    \"n_estimators\": 50,\n",
    "    \"max_depth\": 5,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "calculator = RandomForestClassifierCalculator()\n",
    "applier = RandomForestClassifierApplier()\n",
    "\n",
    "print(\"Fitting Model Calculator...\")\n",
    "# fit() returns the model artifact (dictionary containing the sklearn object or params)\n",
    "model_artifact = calculator.fit(X_train_transformed, y_train, rf_config)\n",
    "\n",
    "# Verify we got an artifact\n",
    "print(\"\\nModel Artifact Type:\", type(model_artifact))\n",
    "# In Skyulf's sklearn wrapper, this is the actual fitted sklearn object\n",
    "print(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f37069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Model to Test Data...\n",
      "\n",
      "--- Results ---\n",
      "Test Set Accuracy: 0.8101\n",
      "Sample Predictions: [0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 6. Apply Model (Inference)\n",
    "# Use the Applier with the fitted artifact to predict on Test Data.\n",
    "\n",
    "print(\"Applying Model to Test Data...\")\n",
    "predictions = applier.predict(X_test_transformed, model_artifact)\n",
    "\n",
    "# Calculate Accuracy\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"Test Set Accuracy: {acc:.4f}\")\n",
    "print(\"Sample Predictions:\", predictions[:5].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408fd13",
   "metadata": {},
   "source": [
    "### 4. The 'State' in Action: Saving and Loading\n",
    "This section demonstrates concept.\n",
    "1. We **Simulate the Tailor** (Fit) to generate a JSON artifact.\n",
    "2. We **Save** that JSON to disk (`scaler_state.json`).\n",
    "3. We **Simulate the Factory** (Apply) by loading that JSON from disk and using it to transform data.\n",
    "**Note:** No Python objects are pickled. Only data (JSON) is exchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57376ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [Tailor] Measuring the data (Fitting Scaler)...\n",
      "2. [Shipping] Saving state to 'scaler_state.json'...\n",
      "   File created: c:\\Users\\Murat\\Desktop\\skyulf-mlflow\\docs\\examples\\notebooks\\scaler_state.json\n",
      "   File Content Preview: {\"type\": \"standard_scaler\", \"mean\": [2.330056179775281, 29.498846153846156, 32.5862761235955], \"scal...\n",
      "\n",
      "3. [Factory] Loading state and starting production...\n",
      "   Factory Output (First 3 rows of scaled Age/Fare):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.333901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.103618</td>\n",
       "      <td>-0.425284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>-0.655664</td>\n",
       "      <td>-0.474867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age      Fare\n",
       "709       NaN -0.333901\n",
       "439  0.103618 -0.425284\n",
       "840 -0.655664 -0.474867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from skyulf.preprocessing.scaling import StandardScalerCalculator, StandardScalerApplier\n",
    "\n",
    "# --- 1. The Tailor (Learning State) ---\n",
    "print(\"1. Measuring the data (Fitting Scaler)...\")\n",
    "tailor = StandardScalerCalculator()\n",
    "# Learning the mean/std of Age and Fare\n",
    "tailor_config = {\"params\": {\"columns\": [\"Age\", \"Fare\"]}}\n",
    "learned_state_artifact = tailor.fit(X_train, tailor_config)\n",
    "\n",
    "# --- 2. The Shipment (Saving to JSON) ---\n",
    "print(f\"2. Saving state to 'scaler_state.json'...\")\n",
    "# Note: We use the NumpyEncoder helper we defined earlier to handle numpy float types\n",
    "with open(\"scaler_state.json\", \"w\") as f:\n",
    "    json.dump(learned_state_artifact, f, cls=NumpyEncoder, indent=2)\n",
    "\n",
    "# Verify the file exists\n",
    "print(f\"   File created: {os.path.abspath('scaler_state.json')}\")\n",
    "print(f\"   File Content Preview: {json.dumps(learned_state_artifact, cls=NumpyEncoder)[:100]}...\")\n",
    "\n",
    "# --- 3. The Factory (Loading & Applying) ---\n",
    "print(\"\\n3. [Factory] Loading state and starting production...\")\n",
    "\n",
    "# Simulate a clean slate - we don't need the 'tailor' object anymore!\n",
    "del tailor \n",
    "\n",
    "with open(\"scaler_state.json\", \"r\") as f:\n",
    "    loaded_state_artifact = json.load(f)\n",
    "\n",
    "worker = StandardScalerApplier()\n",
    "# The worker takes the LOADED state and applies it to new data\n",
    "# Note: We use X_test here to show it working on unseen data\n",
    "X_test_scaled = worker.apply(X_test, loaded_state_artifact)\n",
    "\n",
    "print(\"   Factory Output (First 3 rows of scaled Age/Fare):\")\n",
    "display(X_test_scaled[[\"Age\", \"Fare\"]].head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
